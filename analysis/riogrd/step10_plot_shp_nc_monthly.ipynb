{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "airtemp\n",
      "pptrate\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import os, argparse\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.rcsetup as rcsetup\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from netCDF4 import Dataset, num2date \n",
    "from datetime import datetime\n",
    "from descartes.patch import PolygonPatch\n",
    "from PIL import Image\n",
    "\n",
    "conf_file = '/glade/u/home/hongli/work/sharp/basins/tayprk_huc12/scripts_hongli/step9_config_upco.txt'\n",
    "\n",
    "def process_command_line():\n",
    "    '''Parse the commandline'''\n",
    "    parser = argparse.ArgumentParser(description='Script to plot netcdf variables for user specified HUCs and time period.')\n",
    "    parser.add_argument('conf_file',\n",
    "                        help='path of configure file.')\n",
    "    args = parser.parse_args()\n",
    "    return(args)\n",
    "\n",
    "def read_confg_file(conf_file):\n",
    "    '''Read the configuration file'''\n",
    "    conf = []\n",
    "    with open(conf_file, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line and not line.startswith('!'):\n",
    "                conf.append((line.split('!')[0]).strip())\n",
    "    return conf\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    # process command line\n",
    "#     args = process_command_line()\n",
    "    \n",
    "    # read configuration file\n",
    "#     conf = read_confg_file(args.conf_file)\n",
    "    conf = read_confg_file(conf_file)\n",
    "    \n",
    "    geo_file =  conf[0]\n",
    "    nc_file = conf[1]\n",
    "    hucID_file = conf[2]\n",
    "    \n",
    "    var_names = list(map(lambda x: x.strip(), conf[3].split(',')))\n",
    "    start_time_str = conf[4]\n",
    "    end_time_str = conf[5]\n",
    "    output_dir = conf[6]\n",
    "    \n",
    "    start_time = datetime.strptime(start_time_str, '%Y-%m-%d %H:%M:%S')\n",
    "    end_time = datetime.strptime(end_time_str, '%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    try:        \n",
    "        root_dir = os.path.dirname(os.path.realpath(__file__))\n",
    "    except NameError:\n",
    "        root_dir = '/glade/u/home/hongli/work/sharp/basins/tayprk_huc12/scripts_hongli'\n",
    "    if not os.path.exists(os.path.join(root_dir, output_dir)):\n",
    "        os.mkdir(os.path.join(root_dir, output_dir))\n",
    "\n",
    "    # read the IDs to subset\n",
    "    with open(hucID_file, 'r') as f:\n",
    "        ids = [int(x) for x in f]\n",
    "\n",
    "    # subset shapefile based on hucID\n",
    "    geo_handle = gpd.read_file(geo_file)\n",
    "    criterion = geo_handle['HUC12'].map(lambda x: int(x) in ids)\n",
    "        \n",
    "    # subset netcdf based on hucID and time\n",
    "    f = Dataset(nc_file)\n",
    "    hruId = f.variables['hruId'][:]\n",
    "    time = f.variables['time']\n",
    "    time = num2date(time[:], time.units)\n",
    "    \n",
    "    hruId_index = list((map(lambda x: x in ids, hruId.data)))\n",
    "    time_index = list(map(lambda x: (x >= start_time) & (x<= end_time), time))\n",
    "\n",
    "    hruId_subset = list(map(lambda x: str(x), hruId[hruId_index]))\n",
    "    time_subset = time[time_index]\n",
    "    time_subset_str = list(map(lambda x: x.strftime('%Y-%m-%d %H'), time_subset))\n",
    "    if len(hruId_subset) == 0 or len(time_subset_str) == 0:\n",
    "        quit('Please provide a valid hurId or time period.')\n",
    "\n",
    "    var_figs = []\n",
    "    for var_name in var_names:\n",
    "        print(var_name)\n",
    "        \n",
    "        # subset variable data\n",
    "        var_value = f.variables[var_name][:]\n",
    "        var_unit = f.variables[var_name].units\n",
    "        var_longname = f.variables[var_name].long_name\n",
    "        if var_unit == \"K\":\n",
    "            var_value = var_value-273.15  \n",
    "            var_unit = \"$^\\circ$C\"\n",
    "            cmap_str = 'Reds'\n",
    "        elif var_unit == \"kg m-2 s-1\":\n",
    "            var_value = var_value*3*3600 #3hour cumulation\n",
    "            var_unit = \"mm/month\"\n",
    "            cmap_str = 'Blues'\n",
    "        else:\n",
    "            cmap_str = 'jet'\n",
    "        var_subset = var_value[:,hruId_index][time_index,:] \n",
    "\n",
    "        # construct a dataframe with hruId\n",
    "        df1 = pd.DataFrame(data={'HUC12': hruId_subset})\n",
    "#         df2 = pd.DataFrame(var_subset.T, columns=time_subset_str)\n",
    "#         var_frame = pd.concat([df1, df2], axis = 1)\n",
    "    \n",
    "        # calculate monthly average for T /sum for P\n",
    "        df3 = pd.DataFrame(var_subset, index= time_subset, columns=ids)\n",
    "        if var_name == 'airtemp':\n",
    "            df4 = df3.resample('M', label='right').mean()\n",
    "        else:\n",
    "            df4 = df3.resample('M', label='right').sum()\n",
    "        \n",
    "        df5 = df4.T\n",
    "        df5.index=df1.index\n",
    "        df5.columns =df5.columns.map(lambda t: t.strftime('%Y-%m'))\n",
    "        \n",
    "        var_frame = pd.concat([df1, df5], axis = 1)                \n",
    "        var_min = df5.values.min()\n",
    "        var_max = df5.values.max()\n",
    "        \n",
    "        # join netcdf dataframe with shapefile geo-dataframe (once for each variable)\n",
    "        geo_subset = geo_handle[criterion]\n",
    "        geo_subset = geo_subset.merge(var_frame, on='HUC12')\n",
    "\n",
    "        # plot each time step \n",
    "        temp_figs = []  \n",
    "        for t in var_frame.columns[1:]: #the first element is HUC, so don't consider.                       \n",
    "            temp_fig = 'image_'+t+'.png'\n",
    "            temp_figs.append(temp_fig)            \n",
    "            \n",
    "            norm = mpl.colors.Normalize(vmin=var_min,vmax=var_max)\n",
    "            ax  = geo_subset.plot(column = t, legend = False, vmin=var_min, vmax=var_max, \n",
    "                                  cmap = cmap_str, alpha=0.9, edgecolor='grey', linewidth=0.5)\n",
    "            \n",
    "            data = ax.collections[0]\n",
    "            cbar_label = var_longname.capitalize() + ' (' + var_unit+ ')'\n",
    "            plt.colorbar(data, ax=ax, cmap=cmap_str, orientation='horizontal', \n",
    "                         label=cbar_label, shrink=0.7)            \n",
    "\n",
    "            ax.set_xlabel('Longitude', fontsize='large')\n",
    "            ax.set_ylabel('Latitude', fontsize='large')\n",
    "            \n",
    "            title_str = var_longname.capitalize() + '  '+ t\n",
    "            ax.set_title(title_str, fontsize='large')\n",
    "            \n",
    "            fig = plt.gcf()\n",
    "            fig.set_size_inches(10,10)\n",
    "            fig.savefig(os.path.join(root_dir, output_dir, temp_fig))\n",
    "            plt.close(fig)\n",
    "            \n",
    "        # concatenate differnt time step plots into one plot (per variable)    \n",
    "        widths = []\n",
    "        heights = []\n",
    "        var_fig_file = var_name+'.png'\n",
    "        var_figs.append(var_fig_file)\n",
    "        for temp_fig in temp_figs:\n",
    "            im = Image.open(os.path.join(root_dir, output_dir, temp_fig))\n",
    "            widths.append(im.width)\n",
    "            heights.append(im.height)\n",
    "\n",
    "        max_width = max(widths)\n",
    "        total_height = sum(heights)\n",
    "        new_im = Image.new('RGB', (max_width, total_height))\n",
    "\n",
    "        x_offset = 0\n",
    "        for temp_fig in temp_figs:\n",
    "            im = Image.open(os.path.join(root_dir, output_dir, temp_fig))    \n",
    "            new_im.paste(im, (0,x_offset))\n",
    "            x_offset += im.size[1]\n",
    "        new_im.save(os.path.join(root_dir, output_dir, var_fig_file))\n",
    "\n",
    "        for file in os.listdir(os.path.join(root_dir, output_dir)):\n",
    "            if file.startswith('image'):\n",
    "                os.remove(os.path.join(root_dir, output_dir, file))\n",
    "        [os.remove(file) for file in os.getcwd() if file.startswith('image')] \n",
    "        del geo_subset, df1, df3, df4, df5, var_frame\n",
    "\n",
    "    f.close()\n",
    "    del geo_handle\n",
    "\n",
    "    # concatenate different variable plots into one plot    \n",
    "    widths = []\n",
    "    heights = []\n",
    "    output_fig_file = '{0:%Y}'.format(time_subset[0])+'_monthly.png'\n",
    "    for temp_fig in var_figs:\n",
    "        im = Image.open(os.path.join(root_dir, output_dir, temp_fig))\n",
    "        widths.append(im.width)\n",
    "        heights.append(im.height)\n",
    "\n",
    "    max_width = sum(widths)\n",
    "    total_height = max(heights)\n",
    "    new_im = Image.new('RGB', (max_width, total_height))\n",
    "\n",
    "    x_offset = 0\n",
    "    for temp_fig in var_figs:\n",
    "        im = Image.open(os.path.join(root_dir, output_dir, temp_fig))    \n",
    "        new_im.paste(im, (x_offset,0))\n",
    "        x_offset += im.size[0]\n",
    "    new_im.save(os.path.join(root_dir, output_dir, output_fig_file))\n",
    "    \n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check HUC12 order/consistency before concatenating two dataframes\n",
    "a1=df4.T.index.values\n",
    "a2=np.asarray(list(map(lambda x: int(x), df1['HUC12'].values)))\n",
    "sum(a1-a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([535]),)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check teh HUC12 and variable value consistency after geopandas merging\n",
    "np.where(geo_subset['HUC12']=='130100011008')\n",
    "np.where(var_frame['HUC12']=='130100011008')[0]\n",
    "geo_subset['2014-01'][535], var_frame['2014-01'][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ENTER]",
   "language": "python",
   "name": "conda-env-ENTER-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
